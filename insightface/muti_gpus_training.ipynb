{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dell/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/dell/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the retry module or similar alternatives.\n",
      "start\n",
      "times:  1000\n",
      "train_accuracy:  0.01171875\n",
      "train_loss:  42.62245\n",
      "time:  595.178290605545\n",
      "times:  2000\n",
      "train_accuracy:  0.046875\n",
      "train_loss:  39.180023\n",
      "time:  1088.884649515152\n",
      "times:  3000\n",
      "train_accuracy:  0.01953125\n",
      "train_loss:  34.594162\n",
      "time:  1583.919938325882\n",
      "times:  4000\n",
      "train_accuracy:  0.078125\n",
      "train_loss:  32.301476\n",
      "time:  2080.0958297252655\n",
      "times:  5000\n",
      "train_accuracy:  0.05859375\n",
      "train_loss:  30.721973\n",
      "time:  2576.2248845100403\n",
      "times:  6000\n",
      "train_accuracy:  0.171875\n",
      "train_loss:  27.345337\n",
      "time:  3072.2438430786133\n",
      "times:  7000\n",
      "train_accuracy:  0.10546875\n",
      "train_loss:  25.815805\n",
      "time:  3568.2658002376556\n",
      "times:  8000\n",
      "train_accuracy:  0.1953125\n",
      "train_loss:  22.507519\n",
      "time:  4064.954259634018\n",
      "times:  9000\n",
      "train_accuracy:  0.1328125\n",
      "train_loss:  26.671421\n",
      "time:  4561.75318312645\n",
      "times:  10000\n",
      "train_accuracy:  0.2265625\n",
      "train_loss:  22.822392\n",
      "time:  5057.895961046219\n",
      "times:  11000\n",
      "train_accuracy:  0.15625\n",
      "train_loss:  23.935167\n",
      "time:  5554.494505882263\n",
      "times:  12000\n",
      "train_accuracy:  0.22265625\n",
      "train_loss:  22.655605\n",
      "time:  6050.45370721817\n",
      "times:  13000\n",
      "train_accuracy:  0.15625\n",
      "train_loss:  24.792107\n",
      "time:  6548.120913743973\n",
      "times:  14000\n",
      "train_accuracy:  0.21875\n",
      "train_loss:  21.448444\n",
      "time:  7045.32919716835\n",
      "times:  15000\n",
      "train_accuracy:  0.20703125\n",
      "train_loss:  23.082634\n",
      "time:  7541.994274139404\n",
      "times:  16000\n",
      "train_accuracy:  0.28125\n",
      "train_loss:  20.007904\n",
      "time:  8038.691063642502\n",
      "times:  17000\n",
      "train_accuracy:  0.14453125\n",
      "train_loss:  22.603024\n",
      "time:  8535.367082357407\n",
      "times:  18000\n",
      "train_accuracy:  0.23046875\n",
      "train_loss:  19.942188\n",
      "time:  9031.934041500092\n",
      "times:  19000\n",
      "train_accuracy:  0.16796875\n",
      "train_loss:  21.694916\n",
      "time:  9528.275117874146\n",
      "times:  20000\n",
      "train_accuracy:  0.2890625\n",
      "train_loss:  18.946226\n",
      "time:  10025.114581108093\n",
      "times:  21000\n",
      "train_accuracy:  0.19921875\n",
      "train_loss:  21.207184\n",
      "time:  10521.506206512451\n",
      "times:  22000\n",
      "train_accuracy:  0.32421875\n",
      "train_loss:  17.79369\n",
      "time:  11017.9190158844\n",
      "times:  23000\n",
      "train_accuracy:  0.37109375\n",
      "train_loss:  18.015282\n",
      "time:  11514.319422721863\n",
      "times:  24000\n",
      "train_accuracy:  0.32421875\n",
      "train_loss:  17.515945\n",
      "time:  12010.634806632996\n",
      "times:  25000\n",
      "train_accuracy:  0.4140625\n",
      "train_loss:  17.054663\n",
      "time:  12513.24616241455\n",
      "times:  26000\n",
      "train_accuracy:  0.3359375\n",
      "train_loss:  16.85995\n",
      "time:  13011.88336277008\n",
      "times:  27000\n",
      "train_accuracy:  0.40625\n",
      "train_loss:  15.56254\n",
      "time:  13508.830734491348\n",
      "times:  28000\n",
      "train_accuracy:  0.33984375\n",
      "train_loss:  17.222498\n",
      "time:  14006.265756845474\n",
      "times:  29000\n",
      "train_accuracy:  0.4609375\n",
      "train_loss:  14.054207\n",
      "time:  14502.874229192734\n",
      "times:  30000\n",
      "train_accuracy:  0.40234375\n",
      "train_loss:  15.61213\n",
      "time:  15000.201841831207\n",
      "times:  31000\n",
      "train_accuracy:  0.55859375\n",
      "train_loss:  12.912391\n",
      "time:  15514.510239601135\n",
      "times:  32000\n",
      "train_accuracy:  0.3984375\n",
      "train_loss:  15.032775\n",
      "time:  16011.38035416603\n",
      "times:  33000\n",
      "train_accuracy:  0.41796875\n",
      "train_loss:  14.85437\n",
      "time:  16507.98604130745\n",
      "times:  34000\n",
      "train_accuracy:  0.35546875\n",
      "train_loss:  15.694231\n",
      "time:  17003.954647779465\n",
      "times:  35000\n",
      "train_accuracy:  0.46484375\n",
      "train_loss:  13.169455\n",
      "time:  17500.66852593422\n",
      "times:  36000\n",
      "train_accuracy:  0.328125\n",
      "train_loss:  16.340233\n",
      "time:  17996.936427116394\n",
      "times:  37000\n",
      "train_accuracy:  0.515625\n",
      "train_loss:  13.372149\n",
      "time:  18493.27103996277\n",
      "times:  38000\n",
      "train_accuracy:  0.41796875\n",
      "train_loss:  14.254688\n",
      "time:  18990.10444331169\n",
      "times:  39000\n",
      "train_accuracy:  0.515625\n",
      "train_loss:  13.936419\n",
      "time:  19486.79999423027\n",
      "times:  40000\n",
      "train_accuracy:  0.3515625\n",
      "train_loss:  15.7946615\n",
      "time:  19983.326364040375\n",
      "times:  41000\n",
      "train_accuracy:  0.48046875\n",
      "train_loss:  13.363955\n",
      "time:  20479.89068222046\n",
      "times:  42000\n",
      "train_accuracy:  0.41015625\n",
      "train_loss:  14.536701\n",
      "time:  20977.291205644608\n",
      "times:  43000\n",
      "train_accuracy:  0.484375\n",
      "train_loss:  13.13743\n",
      "time:  21473.495882987976\n",
      "times:  44000\n",
      "train_accuracy:  0.40234375\n",
      "train_loss:  13.406631\n",
      "time:  21970.71818470955\n",
      "times:  45000\n",
      "train_accuracy:  0.5\n",
      "train_loss:  12.833856\n",
      "time:  22466.757322072983\n",
      "times:  46000\n",
      "train_accuracy:  0.5859375\n",
      "train_loss:  11.7532215\n",
      "time:  22963.24902820587\n",
      "times:  47000\n",
      "train_accuracy:  0.54296875\n",
      "train_loss:  12.213675\n",
      "time:  23459.324624061584\n",
      "times:  48000\n",
      "train_accuracy:  0.63671875\n",
      "train_loss:  11.211798\n",
      "time:  23955.32548236847\n",
      "times:  49000\n",
      "train_accuracy:  0.4765625\n",
      "train_loss:  12.710096\n",
      "time:  24451.665594100952\n",
      "times:  50000\n",
      "train_accuracy:  0.609375\n",
      "train_loss:  10.905842\n",
      "time:  24948.13888859749\n",
      "times:  51000\n",
      "train_accuracy:  0.51171875\n",
      "train_loss:  12.232178\n",
      "time:  25445.078857183456\n",
      "times:  52000\n",
      "train_accuracy:  0.6796875\n",
      "train_loss:  10.591681\n",
      "time:  25941.080187559128\n",
      "times:  53000\n",
      "train_accuracy:  0.61328125\n",
      "train_loss:  11.230253\n",
      "time:  26438.049642801285\n",
      "times:  54000\n",
      "train_accuracy:  0.70703125\n",
      "train_loss:  9.736275\n",
      "time:  26934.5055205822\n",
      "times:  55000\n",
      "train_accuracy:  0.578125\n",
      "train_loss:  10.469206\n",
      "time:  27430.35596895218\n",
      "times:  56000\n",
      "train_accuracy:  0.68359375\n",
      "train_loss:  10.091602\n",
      "time:  27926.163859128952\n",
      "times:  57000\n",
      "train_accuracy:  0.58203125\n",
      "train_loss:  11.1070385\n",
      "time:  28422.653739452362\n",
      "times:  58000\n",
      "train_accuracy:  0.68359375\n",
      "train_loss:  10.487086\n",
      "time:  28918.935140132904\n",
      "times:  59000\n",
      "train_accuracy:  0.5\n",
      "train_loss:  12.483117\n",
      "time:  29415.28560256958\n",
      "times:  60000\n",
      "train_accuracy:  0.64453125\n",
      "train_loss:  10.3071575\n",
      "time:  29912.22810292244\n",
      "times:  61000\n",
      "train_accuracy:  0.5625\n",
      "train_loss:  12.183899\n",
      "time:  30424.176773786545\n",
      "times:  62000\n",
      "train_accuracy:  0.61328125\n",
      "train_loss:  10.682355\n",
      "time:  30919.49595928192\n",
      "times:  63000\n",
      "train_accuracy:  0.5703125\n",
      "train_loss:  10.867538\n",
      "time:  31415.533853054047\n",
      "times:  64000\n",
      "train_accuracy:  0.64453125\n",
      "train_loss:  10.634344\n",
      "time:  31911.354367256165\n",
      "times:  65000\n",
      "train_accuracy:  0.625\n",
      "train_loss:  10.442066\n",
      "time:  32407.186758756638\n",
      "times:  66000\n",
      "train_accuracy:  0.62109375\n",
      "train_loss:  10.620346\n",
      "time:  32903.250106334686\n",
      "times:  67000\n",
      "train_accuracy:  0.515625\n",
      "train_loss:  11.47184\n",
      "time:  33399.73000693321\n",
      "times:  68000\n",
      "train_accuracy:  0.68359375\n",
      "train_loss:  10.120016\n",
      "time:  33895.29257416725\n",
      "times:  69000\n",
      "train_accuracy:  0.75390625\n",
      "train_loss:  8.595117\n",
      "time:  34391.52613782883\n",
      "times:  70000\n",
      "train_accuracy:  0.625\n",
      "train_loss:  10.407136\n",
      "time:  34887.81983780861\n",
      "times:  71000\n",
      "train_accuracy:  0.7890625\n",
      "train_loss:  8.219763\n",
      "time:  35383.51214838028\n",
      "times:  72000\n",
      "train_accuracy:  0.7109375\n",
      "train_loss:  9.341136\n",
      "time:  35880.16183590889\n",
      "times:  73000\n",
      "train_accuracy:  0.75390625\n",
      "train_loss:  8.486992\n",
      "time:  36376.655401945114\n",
      "times:  74000\n",
      "train_accuracy:  0.7265625\n",
      "train_loss:  9.267599\n",
      "time:  36873.14245390892\n",
      "times:  75000\n",
      "train_accuracy:  0.7734375\n",
      "train_loss:  8.888863\n",
      "time:  37368.79778265953\n",
      "times:  76000\n",
      "train_accuracy:  0.734375\n",
      "train_loss:  9.267376\n",
      "time:  37864.49595928192\n",
      "times:  77000\n",
      "train_accuracy:  0.8828125\n",
      "train_loss:  7.016877\n",
      "time:  38360.725805044174\n",
      "times:  78000\n",
      "train_accuracy:  0.703125\n",
      "train_loss:  8.942194\n",
      "time:  38856.319598436356\n",
      "times:  79000\n",
      "train_accuracy:  0.8046875\n",
      "train_loss:  7.945648\n",
      "time:  39351.62693619728\n",
      "times:  80000\n",
      "train_accuracy:  0.73828125\n",
      "train_loss:  7.5721645\n",
      "time:  39846.781908750534\n",
      "times:  81000\n",
      "train_accuracy:  0.734375\n",
      "train_loss:  8.894588\n",
      "time:  40342.61817717552\n",
      "times:  82000\n",
      "train_accuracy:  0.7265625\n",
      "train_loss:  8.334757\n",
      "time:  40838.172317028046\n",
      "times:  83000\n",
      "train_accuracy:  0.796875\n",
      "train_loss:  7.78671\n",
      "time:  41334.87653660774\n",
      "times:  84000\n",
      "train_accuracy:  0.73046875\n",
      "train_loss:  9.145713\n",
      "time:  41831.15923285484\n",
      "times:  85000\n",
      "train_accuracy:  0.84375\n",
      "train_loss:  7.630925\n",
      "time:  42327.78864312172\n",
      "times:  86000\n",
      "train_accuracy:  0.73046875\n",
      "train_loss:  8.264221\n",
      "time:  42824.68432831764\n",
      "times:  87000\n",
      "train_accuracy:  0.85546875\n",
      "train_loss:  6.752016\n",
      "time:  43320.701545000076\n",
      "times:  88000\n",
      "train_accuracy:  0.734375\n",
      "train_loss:  8.085661\n",
      "time:  43815.96671414375\n",
      "times:  89000\n",
      "train_accuracy:  0.83203125\n",
      "train_loss:  7.1523085\n",
      "time:  44311.66537690163\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "times:  90000\n",
      "train_accuracy:  0.75390625\n",
      "train_loss:  8.081097\n",
      "time:  44807.451597929\n",
      "times:  91000\n",
      "train_accuracy:  0.8671875\n",
      "train_loss:  6.4140277\n",
      "time:  45319.8419213295\n",
      "times:  92000\n",
      "train_accuracy:  0.89453125\n",
      "train_loss:  6.598339\n",
      "time:  45815.36218595505\n",
      "times:  93000\n",
      "train_accuracy:  0.83203125\n",
      "train_loss:  6.8668394\n",
      "time:  46311.22509884834\n",
      "times:  94000\n",
      "train_accuracy:  0.8828125\n",
      "train_loss:  6.65021\n",
      "time:  46805.974585056305\n",
      "times:  95000\n",
      "train_accuracy:  0.84375\n",
      "train_loss:  6.8617525\n",
      "time:  47301.11820626259\n",
      "times:  96000\n",
      "train_accuracy:  0.89453125\n",
      "train_loss:  5.9464245\n",
      "time:  47797.04121637344\n",
      "times:  97000\n",
      "train_accuracy:  0.89453125\n",
      "train_loss:  5.8348184\n",
      "time:  48292.94453549385\n",
      "times:  98000\n",
      "train_accuracy:  0.890625\n",
      "train_loss:  6.1195574\n",
      "time:  48788.99401283264\n",
      "times:  99000\n",
      "train_accuracy:  0.8515625\n",
      "train_loss:  7.298297\n",
      "time:  49284.557185173035\n",
      "times:  100000\n",
      "train_accuracy:  0.9453125\n",
      "train_loss:  5.522714\n",
      "time:  49779.97583985329\n",
      "times:  101000\n",
      "train_accuracy:  0.83984375\n",
      "train_loss:  6.4776883\n",
      "time:  50275.11796545982\n",
      "times:  102000\n",
      "train_accuracy:  0.89453125\n",
      "train_loss:  5.8076096\n",
      "time:  50770.822900772095\n",
      "times:  103000\n",
      "train_accuracy:  0.8671875\n",
      "train_loss:  6.5175247\n",
      "time:  51266.41661095619\n",
      "times:  104000\n",
      "train_accuracy:  0.92578125\n",
      "train_loss:  5.7737184\n",
      "time:  51762.55948114395\n",
      "times:  105000\n",
      "train_accuracy:  0.8828125\n",
      "train_loss:  6.3712025\n",
      "time:  52259.62429499626\n",
      "times:  106000\n",
      "train_accuracy:  0.89453125\n",
      "train_loss:  5.6576424\n",
      "time:  52756.6550347805\n",
      "times:  107000\n",
      "train_accuracy:  0.87109375\n",
      "train_loss:  6.0577393\n",
      "time:  53252.952900886536\n",
      "times:  108000\n",
      "train_accuracy:  0.859375\n",
      "train_loss:  5.803976\n",
      "time:  53749.00332903862\n",
      "times:  109000\n",
      "train_accuracy:  0.85546875\n",
      "train_loss:  5.751832\n",
      "time:  54245.62295079231\n",
      "times:  110000\n",
      "train_accuracy:  0.88671875\n",
      "train_loss:  5.767458\n",
      "time:  54741.37460541725\n",
      "times:  111000\n",
      "train_accuracy:  0.83984375\n",
      "train_loss:  6.2506576\n",
      "time:  55237.48644447327\n",
      "times:  112000\n",
      "train_accuracy:  0.85546875\n",
      "train_loss:  6.0328894\n",
      "time:  55733.42581343651\n",
      "times:  113000\n",
      "train_accuracy:  0.859375\n",
      "train_loss:  6.490448\n",
      "time:  56229.38081407547\n",
      "times:  114000\n",
      "train_accuracy:  0.87109375\n",
      "train_loss:  5.7933216\n",
      "time:  56726.01929426193\n",
      "times:  115000\n",
      "train_accuracy:  0.90625\n",
      "train_loss:  5.7372055\n",
      "time:  57221.275512218475\n",
      "times:  116000\n",
      "train_accuracy:  0.89453125\n",
      "train_loss:  5.372278\n",
      "time:  57717.72246217728\n",
      "times:  117000\n",
      "train_accuracy:  0.89453125\n",
      "train_loss:  5.5970125\n",
      "time:  58213.8355653286\n",
      "times:  118000\n",
      "train_accuracy:  0.89453125\n",
      "train_loss:  5.209026\n",
      "time:  58709.713096380234\n",
      "times:  119000\n",
      "train_accuracy:  0.90234375\n",
      "train_loss:  5.206667\n",
      "time:  59206.18811869621\n",
      "times:  120000\n",
      "train_accuracy:  0.90625\n",
      "train_loss:  5.1162214\n",
      "time:  59702.73034667969\n",
      "times:  121000\n",
      "train_accuracy:  0.9296875\n",
      "train_loss:  5.0632277\n",
      "time:  60212.24732899666\n",
      "times:  122000\n",
      "train_accuracy:  0.8984375\n",
      "train_loss:  5.2011986\n",
      "time:  60707.539382219315\n",
      "times:  123000\n",
      "train_accuracy:  0.97265625\n",
      "train_loss:  4.655533\n",
      "time:  61202.81457948685\n",
      "times:  124000\n",
      "train_accuracy:  0.90234375\n",
      "train_loss:  5.0863543\n",
      "time:  61698.171469688416\n",
      "times:  125000\n",
      "train_accuracy:  0.93359375\n",
      "train_loss:  4.801504\n",
      "time:  62193.58126831055\n",
      "times:  126000\n",
      "train_accuracy:  0.91015625\n",
      "train_loss:  5.0591097\n",
      "time:  62689.502776145935\n",
      "times:  127000\n",
      "train_accuracy:  0.93359375\n",
      "train_loss:  4.8807135\n",
      "time:  63185.47830462456\n",
      "times:  128000\n",
      "train_accuracy:  0.9296875\n",
      "train_loss:  4.6337013\n",
      "time:  63681.90477657318\n",
      "times:  129000\n",
      "train_accuracy:  0.953125\n",
      "train_loss:  4.6691456\n",
      "time:  64176.963549137115\n",
      "times:  130000\n",
      "train_accuracy:  0.92578125\n",
      "train_loss:  4.798162\n",
      "time:  64671.090826034546\n",
      "times:  131000\n",
      "train_accuracy:  0.9375\n",
      "train_loss:  4.801735\n",
      "time:  65166.174349308014\n",
      "times:  132000\n",
      "train_accuracy:  0.94140625\n",
      "train_loss:  4.714496\n",
      "time:  65662.52961611748\n",
      "times:  133000\n",
      "train_accuracy:  0.9609375\n",
      "train_loss:  4.559839\n",
      "time:  66157.09542679787\n",
      "times:  134000\n",
      "train_accuracy:  0.9375\n",
      "train_loss:  4.591323\n",
      "time:  66652.42358231544\n",
      "times:  135000\n",
      "train_accuracy:  0.96484375\n",
      "train_loss:  4.4001226\n",
      "time:  67147.84928584099\n",
      "times:  136000\n",
      "train_accuracy:  0.9140625\n",
      "train_loss:  4.5727983\n",
      "time:  67642.6784722805\n",
      "times:  137000\n",
      "train_accuracy:  0.95703125\n",
      "train_loss:  4.5229893\n",
      "time:  68137.27762269974\n",
      "times:  138000\n",
      "train_accuracy:  0.953125\n",
      "train_loss:  4.333053\n",
      "time:  68632.18937969208\n",
      "times:  139000\n",
      "train_accuracy:  0.9296875\n",
      "train_loss:  4.5101914\n",
      "time:  69127.66633439064\n",
      "times:  140000\n",
      "train_accuracy:  0.96875\n",
      "train_loss:  4.1968393\n",
      "time:  69622.53207445145\n",
      "times:  141000\n",
      "train_accuracy:  0.97265625\n",
      "train_loss:  4.2244134\n",
      "time:  70117.61607575417\n",
      "times:  142000\n",
      "train_accuracy:  0.9609375\n",
      "train_loss:  4.285859\n",
      "time:  70612.69447422028\n",
      "times:  143000\n",
      "train_accuracy:  0.9765625\n",
      "train_loss:  4.1590185\n",
      "time:  71107.74239897728\n",
      "times:  144000\n",
      "train_accuracy:  0.99609375\n",
      "train_loss:  4.073677\n",
      "time:  71603.18139696121\n",
      "times:  145000\n",
      "train_accuracy:  0.9765625\n",
      "train_loss:  4.165122\n",
      "time:  72099.22866845131\n",
      "times:  146000\n",
      "train_accuracy:  0.9765625\n",
      "train_loss:  4.0780926\n",
      "time:  72594.57682919502\n",
      "times:  147000\n",
      "train_accuracy:  0.9765625\n",
      "train_loss:  4.078532\n",
      "time:  73089.98728704453\n",
      "times:  148000\n",
      "train_accuracy:  0.96484375\n",
      "train_loss:  4.179227\n",
      "time:  73585.71312451363\n",
      "times:  149000\n",
      "train_accuracy:  0.96484375\n",
      "train_loss:  4.0876913\n",
      "time:  74081.40839648247\n",
      "times:  150000\n",
      "train_accuracy:  0.984375\n",
      "train_loss:  4.0019503\n",
      "time:  74577.56109571457\n",
      "times:  151000\n",
      "train_accuracy:  0.97265625\n",
      "train_loss:  3.9938855\n",
      "time:  75090.10882759094\n",
      "times:  152000\n",
      "train_accuracy:  0.97265625\n",
      "train_loss:  3.9832242\n",
      "time:  75584.89739727974\n",
      "times:  153000\n",
      "train_accuracy:  0.97265625\n",
      "train_loss:  3.9796598\n",
      "time:  76081.07631087303\n",
      "times:  154000\n",
      "train_accuracy:  0.97265625\n",
      "train_loss:  3.9770474\n",
      "time:  76578.33942222595\n",
      "times:  155000\n",
      "train_accuracy:  0.97265625\n",
      "train_loss:  3.9949832\n",
      "time:  77076.15373635292\n",
      "times:  156000\n",
      "train_accuracy:  0.9765625\n",
      "train_loss:  3.9136786\n",
      "time:  77572.90157175064\n",
      "times:  157000\n",
      "train_accuracy:  0.9765625\n",
      "train_loss:  3.8712802\n",
      "time:  78069.629707098\n",
      "times:  158000\n",
      "train_accuracy:  0.9609375\n",
      "train_loss:  3.9739833\n",
      "time:  78566.26167011261\n",
      "times:  159000\n",
      "train_accuracy:  0.96484375\n",
      "train_loss:  3.9167154\n",
      "time:  79063.09544348717\n",
      "times:  160000\n",
      "train_accuracy:  0.984375\n",
      "train_loss:  3.804893\n",
      "time:  79559.59785437584\n",
      "times:  161000\n",
      "train_accuracy:  0.9921875\n",
      "train_loss:  3.7982001\n",
      "time:  80056.08107924461\n",
      "times:  162000\n",
      "train_accuracy:  0.96875\n",
      "train_loss:  3.9203186\n",
      "time:  80552.26039624214\n",
      "times:  163000\n",
      "train_accuracy:  0.984375\n",
      "train_loss:  3.7945452\n",
      "time:  81049.19800233841\n",
      "times:  164000\n",
      "train_accuracy:  0.984375\n",
      "train_loss:  3.776613\n",
      "time:  81546.04032301903\n",
      "times:  165000\n",
      "train_accuracy:  0.98046875\n",
      "train_loss:  3.7429538\n",
      "time:  82042.80279564857\n",
      "times:  166000\n",
      "train_accuracy:  0.98046875\n",
      "train_loss:  3.754181\n",
      "time:  82539.41744232178\n",
      "times:  167000\n",
      "train_accuracy:  0.9921875\n",
      "train_loss:  3.7599845\n",
      "time:  83036.37649178505\n",
      "times:  168000\n",
      "train_accuracy:  0.96484375\n",
      "train_loss:  3.8494577\n",
      "time:  83532.78007936478\n",
      "times:  169000\n",
      "train_accuracy:  0.984375\n",
      "train_loss:  3.7165477\n",
      "time:  84029.70982503891\n",
      "times:  170000\n",
      "train_accuracy:  0.984375\n",
      "train_loss:  3.6815977\n",
      "time:  84526.34403133392\n",
      "times:  171000\n",
      "train_accuracy:  0.9765625\n",
      "train_loss:  3.7155247\n",
      "time:  85022.78528165817\n",
      "times:  172000\n",
      "train_accuracy:  1.0\n",
      "train_loss:  3.6681526\n",
      "time:  85517.76597332954\n",
      "times:  173000\n",
      "train_accuracy:  0.9921875\n",
      "train_loss:  3.6840396\n",
      "time:  86013.22408008575\n",
      "times:  174000\n",
      "train_accuracy:  0.97265625\n",
      "train_loss:  3.7138257\n",
      "time:  86508.66558241844\n",
      "times:  175000\n",
      "train_accuracy:  0.97265625\n",
      "train_loss:  3.859512\n",
      "time:  87004.05422472954\n",
      "times:  176000\n",
      "train_accuracy:  0.9765625\n",
      "train_loss:  3.6985416\n",
      "time:  87500.09578680992\n",
      "times:  177000\n",
      "train_accuracy:  0.984375\n",
      "train_loss:  3.6414464\n",
      "time:  87995.93661236763\n",
      "times:  178000\n",
      "train_accuracy:  0.9921875\n",
      "train_loss:  3.690017\n",
      "time:  88492.02091789246\n",
      "times:  179000\n",
      "train_accuracy:  0.984375\n",
      "train_loss:  3.6949406\n",
      "time:  88987.82318210602\n",
      "times:  180000\n",
      "train_accuracy:  0.96484375\n",
      "train_loss:  3.8347726\n",
      "time:  89483.33392500877\n",
      "times:  181000\n",
      "train_accuracy:  0.9921875\n",
      "train_loss:  3.6271505\n",
      "time:  89994.548609972\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "times:  182000\n",
      "train_accuracy:  0.9921875\n",
      "train_loss:  3.625484\n",
      "time:  90490.17711257935\n",
      "times:  183000\n",
      "train_accuracy:  0.9921875\n",
      "train_loss:  3.5950975\n",
      "time:  90985.28136086464\n",
      "times:  184000\n",
      "train_accuracy:  0.9765625\n",
      "train_loss:  3.6839368\n",
      "time:  91481.56646251678\n",
      "times:  185000\n",
      "train_accuracy:  0.99609375\n",
      "train_loss:  3.6069674\n",
      "time:  91977.77905726433\n",
      "times:  186000\n",
      "train_accuracy:  0.9921875\n",
      "train_loss:  3.5918949\n",
      "time:  92474.18846511841\n",
      "times:  187000\n",
      "train_accuracy:  0.98828125\n",
      "train_loss:  3.5831861\n",
      "time:  92971.08817100525\n",
      "times:  188000\n",
      "train_accuracy:  0.984375\n",
      "train_loss:  3.625761\n",
      "time:  93467.14297509193\n",
      "times:  189000\n",
      "train_accuracy:  0.9921875\n",
      "train_loss:  3.5499883\n",
      "time:  93963.66238951683\n",
      "times:  190000\n",
      "train_accuracy:  0.99609375\n",
      "train_loss:  3.6067781\n",
      "time:  94460.58076095581\n",
      "times:  191000\n",
      "train_accuracy:  0.9765625\n",
      "train_loss:  3.6021938\n",
      "time:  94957.7469086647\n",
      "times:  192000\n",
      "train_accuracy:  0.99609375\n",
      "train_loss:  3.5156093\n",
      "time:  95455.22744631767\n",
      "times:  193000\n",
      "train_accuracy:  0.98046875\n",
      "train_loss:  3.6619473\n",
      "time:  95951.985881567\n",
      "times:  194000\n",
      "train_accuracy:  0.984375\n",
      "train_loss:  3.5497103\n",
      "time:  96449.19890546799\n",
      "times:  195000\n",
      "train_accuracy:  0.984375\n",
      "train_loss:  3.6799781\n",
      "time:  96946.05369234085\n",
      "times:  196000\n",
      "train_accuracy:  0.9921875\n",
      "train_loss:  3.504247\n",
      "time:  97442.75082969666\n",
      "times:  197000\n",
      "train_accuracy:  0.9921875\n",
      "train_loss:  3.501588\n",
      "time:  97939.94025349617\n",
      "times:  198000\n",
      "train_accuracy:  0.99609375\n",
      "train_loss:  3.491991\n",
      "time:  98437.46038794518\n",
      "times:  199000\n",
      "train_accuracy:  0.984375\n",
      "train_loss:  3.53829\n",
      "time:  98934.5911078453\n",
      "times:  200000\n",
      "train_accuracy:  0.9921875\n",
      "train_loss:  3.4679403\n",
      "time:  99431.90654540062\n",
      "times:  201000\n",
      "train_accuracy:  0.98046875\n",
      "train_loss:  3.5095081\n",
      "time:  99928.60827803612\n",
      "times:  202000\n",
      "train_accuracy:  0.97265625\n",
      "train_loss:  3.5408163\n",
      "time:  100425.20657324791\n",
      "times:  203000\n",
      "train_accuracy:  0.96484375\n",
      "train_loss:  3.550602\n",
      "time:  100922.58901000023\n",
      "times:  204000\n",
      "train_accuracy:  0.9921875\n",
      "train_loss:  3.4810638\n",
      "time:  101420.56818819046\n",
      "times:  205000\n",
      "train_accuracy:  0.99609375\n",
      "train_loss:  3.461646\n",
      "time:  101916.93597912788\n",
      "times:  206000\n",
      "train_accuracy:  0.99609375\n",
      "train_loss:  3.435801\n",
      "time:  102414.45387554169\n",
      "times:  207000\n",
      "train_accuracy:  0.99609375\n",
      "train_loss:  3.4180856\n",
      "time:  102911.57674360275\n",
      "times:  208000\n",
      "train_accuracy:  1.0\n",
      "train_loss:  3.4217224\n",
      "time:  103408.48487639427\n",
      "times:  209000\n",
      "train_accuracy:  0.984375\n",
      "train_loss:  3.4248364\n",
      "time:  103905.07926917076\n",
      "times:  210000\n",
      "train_accuracy:  0.984375\n",
      "train_loss:  3.4694805\n",
      "time:  104402.04068470001\n",
      "times:  211000\n",
      "train_accuracy:  0.98828125\n",
      "train_loss:  3.4419246\n",
      "time:  104913.6453037262\n",
      "times:  212000\n",
      "train_accuracy:  0.98828125\n",
      "train_loss:  3.41957\n",
      "time:  105409.60215640068\n",
      "times:  213000\n",
      "train_accuracy:  0.9921875\n",
      "train_loss:  3.3775077\n",
      "time:  105905.30149960518\n",
      "times:  214000\n",
      "train_accuracy:  0.99609375\n",
      "train_loss:  3.3698566\n",
      "time:  106401.33106040955\n",
      "times:  215000\n",
      "train_accuracy:  0.98828125\n",
      "train_loss:  3.385733\n",
      "time:  106897.00047636032\n",
      "times:  216000\n",
      "train_accuracy:  0.99609375\n",
      "train_loss:  3.378292\n",
      "time:  107393.09894609451\n",
      "times:  217000\n",
      "train_accuracy:  1.0\n",
      "train_loss:  3.342173\n",
      "time:  107889.03045606613\n",
      "times:  218000\n",
      "train_accuracy:  0.99609375\n",
      "train_loss:  3.3458285\n",
      "time:  108385.01126384735\n",
      "times:  219000\n",
      "train_accuracy:  0.9921875\n",
      "train_loss:  3.3767653\n",
      "time:  108881.99363255501\n",
      "times:  220000\n",
      "train_accuracy:  0.99609375\n",
      "train_loss:  3.3601565\n",
      "time:  109378.26651382446\n",
      "times:  221000\n",
      "train_accuracy:  0.99609375\n",
      "train_loss:  3.3259482\n",
      "time:  109874.61292910576\n",
      "times:  222000\n",
      "train_accuracy:  0.9765625\n",
      "train_loss:  3.5379775\n",
      "time:  110371.31261467934\n",
      "times:  223000\n",
      "train_accuracy:  0.9921875\n",
      "train_loss:  3.303992\n",
      "time:  110867.80399179459\n",
      "times:  224000\n",
      "train_accuracy:  0.9921875\n",
      "train_loss:  3.3078966\n",
      "time:  111363.736109972\n",
      "times:  225000\n",
      "train_accuracy:  0.98828125\n",
      "train_loss:  3.3327394\n",
      "time:  111860.06337285042\n",
      "times:  226000\n",
      "train_accuracy:  0.98828125\n",
      "train_loss:  3.4338307\n",
      "time:  112355.71141576767\n",
      "times:  227000\n",
      "train_accuracy:  1.0\n",
      "train_loss:  3.2934709\n",
      "time:  112851.86818647385\n",
      "times:  228000\n",
      "train_accuracy:  0.9921875\n",
      "train_loss:  3.2913969\n",
      "time:  113348.29787778854\n",
      "times:  229000\n",
      "train_accuracy:  0.99609375\n",
      "train_loss:  3.2940278\n",
      "time:  113844.96240758896\n",
      "times:  230000\n",
      "train_accuracy:  0.98828125\n",
      "train_loss:  3.2779179\n",
      "time:  114341.77247810364\n",
      "times:  231000\n",
      "train_accuracy:  0.98828125\n",
      "train_loss:  3.3408995\n",
      "time:  114838.64455366135\n",
      "times:  232000\n",
      "train_accuracy:  0.99609375\n",
      "train_loss:  3.2633715\n",
      "time:  115335.50651669502\n",
      "times:  233000\n",
      "train_accuracy:  0.98828125\n",
      "train_loss:  3.3874173\n",
      "time:  115831.43806147575\n",
      "times:  234000\n",
      "train_accuracy:  0.98828125\n",
      "train_loss:  3.2981489\n",
      "time:  116328.04874587059\n",
      "times:  235000\n",
      "train_accuracy:  0.9921875\n",
      "train_loss:  3.2435212\n",
      "time:  116824.29429721832\n",
      "times:  236000\n",
      "train_accuracy:  0.99609375\n",
      "train_loss:  3.2402549\n",
      "time:  117320.3146314621\n",
      "times:  237000\n",
      "train_accuracy:  1.0\n",
      "train_loss:  3.2187915\n",
      "time:  117816.4215350151\n",
      "times:  238000\n",
      "train_accuracy:  0.9921875\n",
      "train_loss:  3.2315083\n",
      "time:  118312.29561281204\n",
      "times:  239000\n",
      "train_accuracy:  0.99609375\n",
      "train_loss:  3.21864\n",
      "time:  118808.14113807678\n",
      "times:  240000\n",
      "train_accuracy:  1.0\n",
      "train_loss:  3.2198014\n",
      "time:  119304.16842031479\n",
      "times:  241000\n",
      "train_accuracy:  0.99609375\n",
      "train_loss:  3.2156725\n",
      "time:  119817.1450791359\n",
      "times:  242000\n",
      "train_accuracy:  0.9921875\n",
      "train_loss:  3.2108161\n",
      "time:  120313.16433215141\n",
      "times:  243000\n",
      "train_accuracy:  0.99609375\n",
      "train_loss:  3.195228\n",
      "time:  120809.68971776962\n",
      "times:  244000\n",
      "train_accuracy:  0.99609375\n",
      "train_loss:  3.180385\n",
      "time:  121306.59693527222\n",
      "times:  245000\n",
      "train_accuracy:  0.99609375\n",
      "train_loss:  3.173256\n",
      "time:  121802.33830213547\n",
      "times:  246000\n",
      "train_accuracy:  0.99609375\n",
      "train_loss:  3.1767597\n",
      "time:  122298.80055904388\n",
      "times:  247000\n",
      "train_accuracy:  1.0\n",
      "train_loss:  3.1600325\n",
      "time:  122795.79486894608\n",
      "times:  248000\n",
      "train_accuracy:  0.9921875\n",
      "train_loss:  3.159531\n",
      "time:  123291.80069899559\n",
      "times:  249000\n",
      "train_accuracy:  0.9921875\n",
      "train_loss:  3.1748385\n",
      "time:  123787.82767796516\n",
      "times:  250000\n",
      "train_accuracy:  0.9921875\n",
      "train_loss:  3.170076\n",
      "time:  124284.805341959\n",
      "times:  251000\n",
      "train_accuracy:  0.984375\n",
      "train_loss:  3.186781\n",
      "time:  124781.26168179512\n",
      "times:  252000\n",
      "train_accuracy:  0.98828125\n",
      "train_loss:  3.1642108\n",
      "time:  125277.32841897011\n",
      "times:  253000\n",
      "train_accuracy:  0.99609375\n",
      "train_loss:  3.123539\n",
      "time:  125773.81872653961\n",
      "times:  254000\n",
      "train_accuracy:  1.0\n",
      "train_loss:  3.1131003\n",
      "time:  126270.21917486191\n",
      "times:  255000\n",
      "train_accuracy:  0.98046875\n",
      "train_loss:  3.19767\n",
      "time:  126766.33760881424\n",
      "times:  256000\n",
      "train_accuracy:  0.99609375\n",
      "train_loss:  3.1176164\n",
      "time:  127263.23023200035\n",
      "times:  257000\n",
      "train_accuracy:  0.9921875\n",
      "train_loss:  3.1141505\n",
      "time:  127759.46584248543\n",
      "times:  258000\n",
      "train_accuracy:  0.99609375\n",
      "train_loss:  3.1156988\n",
      "time:  128255.81851482391\n",
      "times:  259000\n",
      "train_accuracy:  0.9921875\n",
      "train_loss:  3.1314373\n",
      "time:  128752.20064163208\n",
      "times:  260000\n",
      "train_accuracy:  1.0\n",
      "train_loss:  3.0752015\n",
      "time:  129249.04358625412\n",
      "times:  261000\n",
      "train_accuracy:  1.0\n",
      "train_loss:  3.0683208\n",
      "time:  129745.0532207489\n",
      "times:  262000\n",
      "train_accuracy:  0.99609375\n",
      "train_loss:  3.0833206\n",
      "time:  130241.64990592003\n",
      "times:  263000\n",
      "train_accuracy:  1.0\n",
      "train_loss:  3.0605378\n",
      "time:  130737.81457829475\n",
      "times:  264000\n",
      "train_accuracy:  1.0\n",
      "train_loss:  3.0669904\n",
      "time:  131234.3960442543\n",
      "times:  265000\n",
      "train_accuracy:  1.0\n",
      "train_loss:  3.0459373\n",
      "time:  131731.39381313324\n",
      "times:  266000\n",
      "train_accuracy:  0.98828125\n",
      "train_loss:  3.0863578\n",
      "time:  132227.38705468178\n",
      "times:  267000\n",
      "train_accuracy:  1.0\n",
      "train_loss:  3.0418994\n",
      "time:  132723.81148147583\n",
      "times:  268000\n",
      "train_accuracy:  0.98828125\n",
      "train_loss:  3.0523248\n",
      "time:  133220.23741674423\n",
      "times:  269000\n",
      "train_accuracy:  1.0\n",
      "train_loss:  3.0229163\n",
      "time:  133715.87047338486\n",
      "times:  270000\n",
      "train_accuracy:  0.98828125\n",
      "train_loss:  3.046655\n",
      "time:  134212.16587257385\n",
      "times:  271000\n",
      "train_accuracy:  0.984375\n",
      "train_loss:  3.041754\n",
      "time:  134724.37838077545\n",
      "times:  272000\n",
      "train_accuracy:  1.0\n",
      "train_loss:  3.0189924\n",
      "time:  135220.12829852104\n",
      "times:  273000\n",
      "train_accuracy:  0.9921875\n",
      "train_loss:  3.0013797\n",
      "time:  135716.2571747303\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "times:  274000\n",
      "train_accuracy:  1.0\n",
      "train_loss:  3.0254831\n",
      "time:  136212.51454377174\n",
      "times:  275000\n",
      "train_accuracy:  0.99609375\n",
      "train_loss:  3.0343475\n",
      "time:  136708.19340610504\n",
      "times:  276000\n",
      "train_accuracy:  0.99609375\n",
      "train_loss:  3.03924\n",
      "time:  137204.40947771072\n",
      "times:  277000\n",
      "train_accuracy:  0.99609375\n",
      "train_loss:  2.9883132\n",
      "time:  137700.4250473976\n",
      "times:  278000\n",
      "train_accuracy:  0.984375\n",
      "train_loss:  3.0108333\n",
      "time:  138197.48367476463\n",
      "times:  279000\n",
      "train_accuracy:  0.99609375\n",
      "train_loss:  2.992661\n",
      "time:  138693.2120909691\n",
      "times:  280000\n",
      "train_accuracy:  1.0\n",
      "train_loss:  2.9572234\n",
      "time:  139189.75592899323\n",
      "times:  281000\n",
      "train_accuracy:  0.9921875\n",
      "train_loss:  2.9613483\n",
      "time:  139686.04461431503\n",
      "times:  282000\n",
      "train_accuracy:  0.99609375\n",
      "train_loss:  2.9672074\n",
      "time:  140182.57924580574\n",
      "times:  283000\n",
      "train_accuracy:  0.98828125\n",
      "train_loss:  2.9758303\n",
      "time:  140679.19736981392\n",
      "times:  284000\n",
      "train_accuracy:  0.99609375\n",
      "train_loss:  3.0023866\n",
      "time:  141176.15607500076\n",
      "times:  285000\n",
      "train_accuracy:  0.99609375\n",
      "train_loss:  2.9300163\n",
      "time:  141672.89343810081\n",
      "times:  286000\n",
      "train_accuracy:  0.984375\n",
      "train_loss:  2.972291\n",
      "time:  142169.8808362484\n",
      "times:  287000\n",
      "train_accuracy:  0.99609375\n",
      "train_loss:  2.949089\n",
      "time:  142666.54200601578\n",
      "times:  288000\n",
      "train_accuracy:  1.0\n",
      "train_loss:  2.9199398\n",
      "time:  143163.33276724815\n",
      "times:  289000\n",
      "train_accuracy:  1.0\n",
      "train_loss:  2.918018\n",
      "time:  143660.17370033264\n",
      "times:  290000\n",
      "train_accuracy:  1.0\n",
      "train_loss:  2.9000292\n",
      "time:  144156.77861523628\n",
      "times:  291000\n",
      "train_accuracy:  0.99609375\n",
      "train_loss:  2.898644\n",
      "time:  144652.96767497063\n",
      "times:  292000\n",
      "train_accuracy:  0.99609375\n",
      "train_loss:  2.9022236\n",
      "time:  145149.6080493927\n",
      "times:  293000\n",
      "train_accuracy:  0.99609375\n",
      "train_loss:  2.9091778\n",
      "time:  145645.99594688416\n",
      "times:  294000\n",
      "train_accuracy:  0.99609375\n",
      "train_loss:  2.8955095\n",
      "time:  146142.77211999893\n",
      "times:  295000\n",
      "train_accuracy:  0.98828125\n",
      "train_loss:  3.0187242\n",
      "time:  146638.3315153122\n",
      "times:  296000\n",
      "train_accuracy:  1.0\n",
      "train_loss:  2.8841991\n",
      "time:  147134.32621502876\n",
      "times:  297000\n",
      "train_accuracy:  0.99609375\n",
      "train_loss:  2.9697595\n",
      "time:  147630.58974909782\n",
      "times:  298000\n",
      "train_accuracy:  1.0\n",
      "train_loss:  2.8650851\n",
      "time:  148127.12030386925\n",
      "times:  299000\n",
      "train_accuracy:  0.9921875\n",
      "train_loss:  2.9774976\n",
      "time:  148623.42625284195\n",
      "times:  300000\n",
      "train_accuracy:  1.0\n",
      "train_loss:  2.8454542\n",
      "time:  149119.85398054123\n",
      "times:  301000\n",
      "train_accuracy:  1.0\n",
      "train_loss:  2.8462806\n",
      "time:  149632.43747401237\n",
      "times:  302000\n",
      "train_accuracy:  1.0\n",
      "train_loss:  2.8350656\n",
      "time:  150128.37450885773\n",
      "times:  303000\n",
      "train_accuracy:  1.0\n",
      "train_loss:  2.8312616\n",
      "time:  150624.6926445961\n",
      "times:  304000\n",
      "train_accuracy:  0.99609375\n",
      "train_loss:  2.8448515\n",
      "time:  151121.06758737564\n",
      "times:  305000\n",
      "train_accuracy:  0.99609375\n",
      "train_loss:  2.8274784\n",
      "time:  151617.79754304886\n",
      "times:  306000\n",
      "train_accuracy:  1.0\n",
      "train_loss:  2.8208265\n",
      "time:  152114.1601512432\n",
      "times:  307000\n",
      "train_accuracy:  1.0\n",
      "train_loss:  2.8081706\n",
      "time:  152611.05571961403\n",
      "times:  308000\n",
      "train_accuracy:  0.9921875\n",
      "train_loss:  2.824571\n",
      "time:  153107.221149683\n",
      "times:  309000\n",
      "train_accuracy:  0.99609375\n",
      "train_loss:  2.8093734\n",
      "time:  153604.28788518906\n",
      "times:  310000\n",
      "train_accuracy:  0.99609375\n",
      "train_loss:  2.7965908\n",
      "time:  154100.63500070572\n",
      "times:  311000\n",
      "train_accuracy:  0.99609375\n",
      "train_loss:  2.792594\n",
      "time:  154597.9142882824\n",
      "times:  312000\n",
      "train_accuracy:  0.99609375\n",
      "train_loss:  2.7848086\n",
      "time:  155094.64640927315\n",
      "times:  313000\n",
      "train_accuracy:  0.98046875\n",
      "train_loss:  3.0417552\n",
      "time:  155590.94040203094\n",
      "times:  314000\n",
      "train_accuracy:  1.0\n",
      "train_loss:  2.780818\n",
      "time:  156087.45396852493\n",
      "times:  315000\n",
      "train_accuracy:  0.99609375\n",
      "train_loss:  2.7658691\n",
      "time:  156584.0935356617\n",
      "times:  316000\n",
      "train_accuracy:  0.99609375\n",
      "train_loss:  2.7767956\n",
      "time:  157080.63509821892\n",
      "times:  317000\n",
      "train_accuracy:  0.9921875\n",
      "train_loss:  2.8181043\n",
      "time:  157576.94086623192\n",
      "times:  318000\n",
      "train_accuracy:  0.9921875\n",
      "train_loss:  2.7596557\n",
      "time:  158073.7726199627\n",
      "times:  319000\n",
      "train_accuracy:  1.0\n",
      "train_loss:  2.7600012\n",
      "time:  158570.30496120453\n",
      "times:  320000\n",
      "train_accuracy:  0.98046875\n",
      "train_loss:  2.9667192\n",
      "time:  159067.07958340645\n",
      "times:  321000\n",
      "train_accuracy:  1.0\n",
      "train_loss:  2.7309108\n",
      "time:  159563.61531686783\n",
      "times:  322000\n",
      "train_accuracy:  0.99609375\n",
      "train_loss:  2.7302303\n",
      "time:  160060.73114824295\n",
      "times:  323000\n",
      "train_accuracy:  0.9921875\n",
      "train_loss:  2.833568\n",
      "time:  160557.40240359306\n",
      "times:  324000\n",
      "train_accuracy:  0.9921875\n",
      "train_loss:  2.7348423\n",
      "time:  161054.4168381691\n",
      "times:  325000\n",
      "train_accuracy:  0.99609375\n",
      "train_loss:  2.7587314\n",
      "time:  161550.45974683762\n",
      "times:  326000\n",
      "train_accuracy:  0.9921875\n",
      "train_loss:  2.7229142\n",
      "time:  162047.74820017815\n",
      "times:  327000\n",
      "train_accuracy:  0.99609375\n",
      "train_loss:  2.7206788\n",
      "time:  162544.80407500267\n",
      "times:  328000\n",
      "train_accuracy:  1.0\n",
      "train_loss:  2.6946054\n",
      "time:  163041.8062736988\n",
      "times:  329000\n",
      "train_accuracy:  0.9921875\n",
      "train_loss:  2.709676\n",
      "time:  163539.58570194244\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-9486173aaf7a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m \u001b[0;31m# tensorboard --logdir=/home/dell/Desktop//InsightFace/model/Arcface/\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-9486173aaf7a>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[0mtrain_phase_bn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'train_phase_bn'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m         \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_phase_dropout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_phase_bn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-9486173aaf7a>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(image, label, train_phase_dropout, train_phase_bn)\u001b[0m\n\u001b[1;32m     95\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m                 \u001b[0mimage_batch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel_batch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_images\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_labels\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m                 \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minc_op\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mimage_batch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlabel_batch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_phase_dropout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_phase_bn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m                 \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m                     \u001b[0msummary\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmerged\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mimage_batch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlabel_batch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_phase_dropout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_phase_bn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    903\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 905\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    906\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1138\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1140\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1141\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1142\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1321\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1325\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1310\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1311\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1312\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1418\u001b[0m         return tf_session.TF_Run(\n\u001b[1;32m   1419\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1420\u001b[0;31m             status, run_metadata)\n\u001b[0m\u001b[1;32m   1421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1422\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "\n",
    "@author: friedhelm\n",
    "\"\"\"\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "import tensorflow as tf\n",
    "from train.train_tool import arcface_loss,read_single_tfrecord,average_gradients\n",
    "from core import Arcface_model,config\n",
    "import time\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "def train(image,label,train_phase_dropout,train_phase_bn):\n",
    "\n",
    "    train_images_split = tf.split(image, config.gpu_num)\n",
    "    train_labels_split = tf.split(label, config.gpu_num)      \n",
    "    \n",
    "    global_step = tf.Variable(name='global_step', initial_value=0, trainable=False)\n",
    "    inc_op = tf.assign_add(global_step, 1, name='increment_global_step')    \n",
    "    scale = int(512.0/batch_size)\n",
    "    lr_steps = [scale*s for s in config.lr_steps]\n",
    "    lr_values = [v/scale for v in config.lr_values]\n",
    "    lr = tf.train.piecewise_constant(global_step, boundaries=lr_steps, values=lr_values, name='lr_schedule')\n",
    "    opt = tf.train.MomentumOptimizer(learning_rate=lr, momentum=config.momentum)\n",
    "\n",
    "    embds = []\n",
    "    logits = []\n",
    "    inference_loss = []\n",
    "    wd_loss = []\n",
    "    total_train_loss = []\n",
    "    pred = []\n",
    "    tower_grads = []\n",
    "    update_ops = []\n",
    "    \n",
    "    for i in range(config.gpu_num):\n",
    "        sub_train_images = train_images_split[i]\n",
    "        sub_train_labels = train_labels_split[i]\n",
    "        with tf.device(\"/gpu:%d\"%(i)):\n",
    "            with tf.variable_scope(tf.get_variable_scope(),reuse=(i>0)):\n",
    "                \n",
    "                net, end_points = Arcface_model.get_embd(sub_train_images, train_phase_dropout, train_phase_bn,config.model_params)\n",
    "                        \n",
    "                logit = arcface_loss(net,sub_train_labels,config.s,config.m)\n",
    "                arc_loss = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits = logit , labels = sub_train_labels))\n",
    "                L2_loss = tf.reduce_sum(tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES))\n",
    "                train_loss = arc_loss+L2_loss\n",
    "                \n",
    "                pred.append(tf.to_int32(tf.argmax(tf.nn.softmax(logit),axis=1)))\n",
    "                tower_grads.append(opt.compute_gradients(train_loss))\n",
    "                update_ops.append(tf.get_collection(tf.GraphKeys.UPDATE_OPS))\n",
    "                \n",
    "                embds.append(net)\n",
    "                logits.append(logit)\n",
    "                inference_loss.append(arc_loss)\n",
    "                wd_loss.append(L2_loss)\n",
    "                total_train_loss.append(train_loss)\n",
    "\n",
    "    embds = tf.concat(embds, axis=0)\n",
    "    logits = tf.concat(logits, axis=0)\n",
    "    pred = tf.concat(pred, axis=0)\n",
    "    wd_loss = tf.add_n(wd_loss)/config.gpu_num\n",
    "    inference_loss = tf.add_n(inference_loss)/config.gpu_num\n",
    "    \n",
    "    train_ops = [opt.apply_gradients(average_gradients(tower_grads))]\n",
    "    train_ops.extend(update_ops)\n",
    "    train_op = tf.group(*train_ops) \n",
    "    \n",
    "    with tf.name_scope('loss'):\n",
    "        train_loss = tf.add_n(total_train_loss)/config.gpu_num\n",
    "        tf.summary.scalar('train_loss',train_loss)    \n",
    "\n",
    "    with tf.name_scope('accuracy'):\n",
    "        train_accuracy = tf.reduce_mean(tf.cast(tf.equal(pred, label), tf.float32))\n",
    "        tf.summary.scalar('train_accuracy',train_accuracy) \n",
    "        \n",
    "    saver=tf.train.Saver(max_to_keep=20)\n",
    "    merged=tf.summary.merge_all() \n",
    "    \n",
    "    train_images,train_labels=read_single_tfrecord(addr,batch_size,img_size)\n",
    "    \n",
    "    tf_config = tf.ConfigProto(allow_soft_placement=True)\n",
    "    tf_config.gpu_options.allow_growth = True\n",
    "    with tf.Session(config=tf_config) as sess:\n",
    "        sess.run((tf.global_variables_initializer(),\n",
    "                  tf.local_variables_initializer()))\n",
    "        coord = tf.train.Coordinator()\n",
    "        threads = tf.train.start_queue_runners(sess=sess,coord=coord)\n",
    "        writer_train=tf.summary.FileWriter(\"./model/%s\"%(model_name),sess.graph)\n",
    "        print(\"start\")\n",
    "        train_begin=time.time()\n",
    "        try:\n",
    "            for i in range(1,train_step):                \n",
    "                image_batch,label_batch=sess.run([train_images,train_labels])\n",
    "                sess.run([train_op,inc_op],feed_dict={image:image_batch,label:label_batch,train_phase_dropout:True,train_phase_bn:True})\n",
    "                if(i%100==0):\n",
    "                    summary=sess.run(merged,feed_dict={image:image_batch,label:label_batch,train_phase_dropout:True,train_phase_bn:True})\n",
    "                    writer_train.add_summary(summary,i)\n",
    "#                     print('100-time: ',time.time()-train_begin)\n",
    "                    train_begin=time.time()\n",
    "                if(i%1000==0):\n",
    "                    print('times: ',i)    \n",
    "                    print('train_accuracy: ',sess.run(train_accuracy,feed_dict={image:image_batch,label:label_batch,train_phase_dropout:True,train_phase_bn:True}))\n",
    "                    print('train_loss: ',sess.run(train_loss,{image:image_batch,label:label_batch,train_phase_dropout:True,train_phase_bn:True}))                    \n",
    "                    print('time: ',time.time()-begin)\n",
    "                    if(i%30000==0):\n",
    "                        saver.save(sess,os.path.join(model_path,model_name),global_step=i)\n",
    "        except  tf.errors.OutOfRangeError:\n",
    "            print(\"finished\")\n",
    "        finally:\n",
    "            coord.request_stop()\n",
    "            writer_train.close()\n",
    "        coord.join(threads)\n",
    "\n",
    "        \n",
    "def main():\n",
    "    \n",
    "    with tf.name_scope('input'):\n",
    "        image=tf.placeholder(tf.float32,[batch_size,img_size,img_size,3],name='image')\n",
    "        label=tf.placeholder(tf.int32,[batch_size],name='label')\n",
    "        train_phase_dropout = tf.placeholder(dtype=tf.bool, shape=None, name='train_phase_dropout')\n",
    "        train_phase_bn = tf.placeholder(dtype=tf.bool, shape=None, name='train_phase_bn') \n",
    "\n",
    "        train(image,label,train_phase_dropout,train_phase_bn)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    img_size=config.img_size\n",
    "    batch_size=config.batch_size\n",
    "    addr=config.addrt\n",
    "    model_name=config.model_name\n",
    "    train_step=config.train_step\n",
    "    model_path=config.model_patht\n",
    "    \n",
    "    begin=time.time()\n",
    "\n",
    "    \n",
    "    main()\n",
    "# tensorboard --logdir=/home/dell/Desktop//InsightFace/model/Arcface/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dell/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/dell/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the retry module or similar alternatives.\n",
      "start\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "\n",
    "@author: friedhelm\n",
    "\"\"\"\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "import tensorflow as tf\n",
    "from train.train_tool import arcface_loss,read_single_tfrecord,average_gradients\n",
    "from core import Arcface_model,config\n",
    "import time\n",
    "import os\n",
    "import numpy as np\n",
    "from evaluate.evaluate import evaluation\n",
    "\n",
    "def train(image,label,train_phase_dropout,train_phase_bn):\n",
    "\n",
    "    train_images_split = tf.split(image, config.gpu_num)\n",
    "    train_labels_split = tf.split(label, config.gpu_num)      \n",
    "    \n",
    "    global_step = tf.Variable(name='global_step', initial_value=0, trainable=False)\n",
    "    inc_op = tf.assign_add(global_step, 1, name='increment_global_step')    \n",
    "    scale = int(512.0/batch_size)\n",
    "    lr_steps = [scale*s for s in config.lr_steps]\n",
    "    lr_values = [v/scale for v in config.lr_values]\n",
    "    lr = tf.train.piecewise_constant(global_step, boundaries=lr_steps, values=lr_values, name='lr_schedule')\n",
    "    opt = tf.train.MomentumOptimizer(learning_rate=lr, momentum=config.momentum)\n",
    "\n",
    "    embds = []\n",
    "    logits = []\n",
    "    inference_loss = []\n",
    "    wd_loss = []\n",
    "    total_train_loss = []\n",
    "    pred = []\n",
    "    tower_grads = []\n",
    "    update_ops = []\n",
    "    \n",
    "    for i in range(config.gpu_num):\n",
    "        sub_train_images = train_images_split[i]\n",
    "        sub_train_labels = train_labels_split[i]\n",
    "        with tf.device(\"/gpu:%d\"%(i)):\n",
    "            with tf.variable_scope(tf.get_variable_scope(),reuse=(i>0)):\n",
    "                \n",
    "                net, end_points = Arcface_model.get_embd(sub_train_images, train_phase_dropout, train_phase_bn,config.model_params)\n",
    "                        \n",
    "                logit = arcface_loss(net,sub_train_labels,config.s,config.m)\n",
    "                arc_loss = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits = logit , labels = sub_train_labels))\n",
    "                L2_loss = tf.reduce_sum(tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES))\n",
    "                train_loss = arc_loss+L2_loss\n",
    "                \n",
    "                pred.append(tf.to_int32(tf.argmax(tf.nn.softmax(logit),axis=1)))\n",
    "                tower_grads.append(opt.compute_gradients(train_loss))\n",
    "                update_ops.append(tf.get_collection(tf.GraphKeys.UPDATE_OPS))\n",
    "                \n",
    "                embds.append(net)\n",
    "                logits.append(logit)\n",
    "                inference_loss.append(arc_loss)\n",
    "                wd_loss.append(L2_loss)\n",
    "                total_train_loss.append(train_loss)\n",
    "\n",
    "    embds = tf.concat(embds, axis=0)\n",
    "    logits = tf.concat(logits, axis=0)\n",
    "    pred = tf.concat(pred, axis=0)\n",
    "    wd_loss = tf.add_n(wd_loss)/config.gpu_num\n",
    "    inference_loss = tf.add_n(inference_loss)/config.gpu_num\n",
    "    \n",
    "    train_ops = [opt.apply_gradients(average_gradients(tower_grads))]\n",
    "    train_ops.extend(update_ops)\n",
    "    train_op = tf.group(*train_ops) \n",
    "    \n",
    "    with tf.name_scope('loss'):\n",
    "        train_loss = tf.add_n(total_train_loss)/config.gpu_num\n",
    "        tf.summary.scalar('train_loss',train_loss)    \n",
    "\n",
    "    with tf.name_scope('accuracy'):\n",
    "        train_accuracy = tf.reduce_mean(tf.cast(tf.equal(pred, label), tf.float32))\n",
    "        tf.summary.scalar('train_accuracy',train_accuracy) \n",
    "        \n",
    "    saver=tf.train.Saver(max_to_keep=20)\n",
    "    merged=tf.summary.merge_all() \n",
    "    \n",
    "    train_images,train_labels=read_single_tfrecord(addr,batch_size,img_size)\n",
    "    \n",
    "    tf_config = tf.ConfigProto(allow_soft_placement=True)\n",
    "    tf_config.gpu_options.allow_growth = True\n",
    "    with tf.Session(config=tf_config) as sess:\n",
    "        sess.run((tf.global_variables_initializer(),\n",
    "                  tf.local_variables_initializer()))\n",
    "        coord = tf.train.Coordinator()\n",
    "        threads = tf.train.start_queue_runners(sess=sess,coord=coord)\n",
    "        writer_train=tf.summary.FileWriter(model_path,sess.graph)\n",
    "        print(\"start\")\n",
    "        train_begin=time.time()\n",
    "        try:\n",
    "            for i in range(1,train_step):                \n",
    "                image_batch,label_batch=sess.run([train_images,train_labels])\n",
    "                sess.run([train_op,inc_op],feed_dict={image:image_batch,label:label_batch,train_phase_dropout:True,train_phase_bn:True})\n",
    "                if(i%100==0):\n",
    "                    summary=sess.run(merged,feed_dict={image:image_batch,label:label_batch,train_phase_dropout:True,train_phase_bn:True})\n",
    "                    writer_train.add_summary(summary,i)\n",
    "#                     print('100-time: ',time.time()-train_begin)\n",
    "                    train_begin=time.time()\n",
    "                if(i%1000==0):\n",
    "                    print('times: ',i)    \n",
    "#                     print('train_accuracy: ',sess.run(train_accuracy,feed_dict={image:image_batch,label:label_batch,train_phase_dropout:True,train_phase_bn:True}))\n",
    "#                     print('train_loss: ',sess.run(train_loss,{image:image_batch,label:label_batch,train_phase_dropout:True,train_phase_bn:True}))                    \n",
    "                    print('time: ',time.time()-begin)\n",
    "                if(i%5000==0):\n",
    "                    f.write(\"itrations: %d\"%(i)+'\\n')\n",
    "                    for dataset_path in config.eval_datasets:\n",
    "                        tpr, fpr, accuracy, best_thresholds = evaluation(sess, batch_size, img_size, dataset_path, dropout_flag=config.eval_dropout_flag, bn_flag=config.eval_bn_flag, embd=embd, image=image, train_phase_dropout=train_phase_dropout, train_phase_bn=train_phase_bn) \n",
    "                        print(\"%s datasets get %.3f acc\"%(dataset_path.split(\"/\")[-1].split(\".\")[0],accuracy))\n",
    "                        f.write(\"\\t %s \\t %.3f \\t \\t \"%(dataset_path.split(\"/\")[-1].split(\".\")[0],accuracy)+str(best_thresholds)+'\\n')\n",
    "                    f.write('\\n')\n",
    "                if(i%30000==0):\n",
    "                    saver.save(sess,os.path.join(model_path,model_name),global_step=i)\n",
    "        except  tf.errors.OutOfRangeError:\n",
    "            print(\"finished\")\n",
    "        finally:\n",
    "            coord.request_stop()\n",
    "            writer_train.close()\n",
    "        coord.join(threads)\n",
    "        f.close()\n",
    "\n",
    "        \n",
    "def main():\n",
    "    \n",
    "    with tf.name_scope('input'):\n",
    "        image=tf.placeholder(tf.float32,[batch_size,img_size,img_size,3],name='image')\n",
    "        label=tf.placeholder(tf.int32,[batch_size],name='label')\n",
    "        train_phase_dropout = tf.placeholder(dtype=tf.bool, shape=None, name='train_phase_dropout')\n",
    "        train_phase_bn = tf.placeholder(dtype=tf.bool, shape=None, name='train_phase_bn') \n",
    "\n",
    "        train(image,label,train_phase_dropout,train_phase_bn)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    img_size=config.img_size\n",
    "    batch_size=config.batch_size\n",
    "    addr=config.addrt\n",
    "    model_name=config.model_name\n",
    "    train_step=config.train_step\n",
    "    model_path=config.model_patht\n",
    "    \n",
    "    begin=time.time()\n",
    "    \n",
    "    f = open(\"./eval_record.txt\", 'w')\n",
    "    f.write(\"\\t dataset \\t accuracy \\t best_thresholds \\t\"+'\\n')    \n",
    "    main()\n",
    "# tensorboard --logdir=/home/dell/Desktop/insightface/model/Arcface_model/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
